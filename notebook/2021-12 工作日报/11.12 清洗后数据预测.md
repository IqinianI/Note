#### 预测

预测清洗出的三个时期的2000例数据

- 手动分割数据集，调用8块gpu

- 预测

  ​	    INPUT_FOLDER: 测试数据地址OUTPUT_FOLDER： 分割数据存放地址CONFIGURATION： 使用的什么架构，2d or 3d_fullres or 3d_cascade_fullres等

  ```python
  export CUDA_VISIBLE_DEVICES=X
  nohup nnUNet_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -t TASK_NAME_OR_ID -m CONFIGURATION >> log_path &
  
  nohup nnUNet_predict -i /workspace/dataset/pred_for_entropy/ps_test_0 -o /workspace/dataset/pred_for_entropy/ps_pred -t 998 -m 3d_cascade_fullres -f 4 >> /workspace/dataset/pred_for_entropy/log/ps.log &
  ```



#### 数据分析

- 统计清洗出的数据相关信息（每个时期数据总量等）
- 统计每个时期不同组织的体积大小、连通区域个数，分析异常分布数据

```python
import os
import shutil
import json
import numpy as np
import SimpleITK as sitk
import skimage.measure as measure


#read nii

def get_area(img_arr):
    """get connected areas

    Args:
        img_arr (ndarray): image array

    Returns:
        list: Sorted connected region,descending
    """
    print('area_label', np.unique(img_arr))
    label = measure.label(img_arr, connectivity=2)
    props = measure.regionprops(label)

    area_info = []

    for i in range(len(props)):
        area_info.append({"voxel": int(props[i].area), "loc": props[i].bbox, "centroid": props[i].centroid})

    sorted_area = sorted(area_info, key=lambda area_info: area_info['voxel'], reverse=True)

    return sorted_area   
    
def load_nii(filepath):
    """read NIFTI image file and save loaction infomation

    Args:
        filepath (str): file path
        channels_last (bool): (x,y,z)

    Returns:
        dict: iamge array and related infomation
    """

    image = sitk.ReadImage(filepath)
    data_arr = sitk.GetArrayFromImage(image).astype(np.float32)

    origin = image.GetOrigin()
    direction = image.GetDirection()
    space = image.GetSpacing()
    cases_dic = {'data_arr': data_arr, 'origin': origin, 'direction': direction, 'space': space}
    return cases_dic
 
def calculate_target_size(infos, spacings):
    real_size = spacings[0]*spacings[2]*spacings[1]
    volume_sum=0
    for i, info in enumerate(infos):
        volume=real_size*info["voxel"]
        info["volume"]=int(volume)
        info["id"]=int(i)
        volume_sum+=volume
    # if len(infos) == 0:
    #     info["volume"]=int(0)
    #     info["id"]=int(-1) 
    return volume_sum

def change_label(pred_arr,tag):
    pred_cp=pred_arr.copy()
    # ps
    # if tag=='kidney':
    #     pred_cp[pred_cp==1]=0
    #     pred_cp[pred_cp==2]=1
    # if tag=='stone':
    #     pred_cp[pred_cp==2]=0
    # if tag=='ps_all':
    #     pred_cp[pred_cp>1]=1
    # px
    # if tag=='px_all':
    #     pred_cp=pred_cp

    
    # pz
    if tag=='pz':
        pred_cp[pred_cp<3]=0
        pred_cp[pred_cp==3]=1

    if tag=='sz':
        pred_cp[pred_cp==1]=0
        pred_cp[pred_cp==2]=1
        pred_cp[pred_cp>2]=0
    if tag=='artery':
        pred_cp[pred_cp>1]=0
    if tag=='cta_all':
        pred_cp[pred_cp>1]=1
    return pred_cp

def to_json(path,json_file):
    with open(path,'w') as f:
        json.dump(json_file,f)
        
# get voxel 
if __name__=="__main__":
    input_path='/workspace/nn_Unet/nnUnet_test/cta_new_pred'
    json_path='/workspace/nn_Unet/nnUnet_test/cta_analysis.json'
    data_analysis_json=[]
    
    filename=os.listdir(input_path)
    for file in filename:
        suffix=file.split('/')[-1].split('.')[0]
        case_name=suffix.split('_',1)[0]
        stage=suffix.split('_',1)[1]
        
        file_path=os.path.join(input_path,file)
        pred=load_nii(file_path)
        pred_arr=pred['data_arr']
        spacing=pred['space']

        label_num=np.unique(pred_arr)
        # map={0:'ps_all',1:'stone',2:'kidney'}
        # map={0:'px_all'}
        map={0:'cta_all',1:'artery',2:'sz',3:'pz'}
        for i in range(len(map)):
            
            tag=map[i]
            pred_change=change_label(pred_arr,tag)
               
            info=get_area(pred_change)
    
            prop_nums=len(info)
            volume_sum=calculate_target_size(info,spacing)
        # print(volume_sum)
            data_analysis_dict={
                'case_name':case_name,
                'stage':stage,
                'tissue':tag,
                'props_nums':int(prop_nums),
                'volume_sum':int(volume_sum),
                'info':info
            }
            data_analysis_json.append(data_analysis_dict)

    # print(data_analysis_json)
    to_json(json_path,data_analysis_json)
    
```



### 开会

和卢博就肾部项目开会

<img src="D:\notebook\imgs\image-20211112183509659.png" alt="image-20211112183509659" style="zoom:33%;" />

### 新数据预测结果评估

wd0405_ps_1_125_0000     120个结石

![image-20211113032036522](D:\notebook\imgs\image-20211113032036522.png)

 

wd0689_ps_1_125  57 个连通域

![image-20211113033106686](D:\notebook\imgs\image-20211113033106686.png)



wd0355_ps_1_250_0000  17个连通域

![image-20211113035048706](D:\notebook\imgs\image-20211113035048706.png)



wd0815_ps_0_125.nii.gz   肾的体积是0，没有预测出肾

![image-20211113035903195](D:\notebook\imgs\image-20211113035903195.png)



wd0386_pz_0_125.nii.gz   髓质体积很小  7544 mm， 肾造影剂的亮度过高，肾无法预测出来

![image-20211113041229199](D:\notebook\imgs\image-20211113041229199.png)



wd0562_px_1_250_0000   集合系统体积体积小  。  右肾没有造影剂显影